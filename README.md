# ProjetoNTTData - Energia El√©trica
# ‚ö°Ô∏è Pipeline de Energia: Ingest√£o, Tratamento e An√°lise (Databricks/PySpark)

## üéØ Objetivo do Projeto

Este projeto implementa um pipeline de ETL (Extract, Transform, Load) completo para ingest√£o, limpeza, transforma√ß√£o e modelagem de dados de consumo e custo de energia. O objetivo √© fornecer conjuntos de dados anal√≠ticos prontos (Data Warehouse/Camada Gold) para relat√≥rios de Business Intelligence (BI) e *data science*.

O pipeline foi constru√≠do seguindo a arquitetura **Medalh√£o (Bronze, Silver, Gold)**, utilizando o **Databricks** como plataforma unificada e **PySpark/SQL** como linguagem de processamento.

---

## üèóÔ∏è Arquitetura e Tecnologia

| Componente | Tecnologia Principal | Fun√ß√£o |
| :--- | :--- | :--- |
| **Plataforma** | **Databricks** | Ambiente unificado para desenvolvimento e execu√ß√£o de jobs Spark. |
| **Armazenamento** | **Delta Lake** | Formato de tabela aberta para garantir atomicidade, consist√™ncia, isolamento e durabilidade (ACID) e versionamento dos dados. |
| **Processamento** | **PySpark** e **SQL** | Linguagem principal para manipula√ß√£o de DataFrames e transforma√ß√µes de dados. |
| **Modelagem** | **Dimensional** | Implementa√ß√£o de tabelas Fato e Dimens√£o na Camada Gold. |

---

## üåä Fluxo de Dados (Arquitetura Medalh√£o)

| Camada | Prop√≥sito | Principais A√ß√µes |
| :--- | :--- | :--- |
| **Bronze** | Ingest√£o bruta (Landing Zone) | Ingest√£o inicial de CSVs. Cria√ß√£o de metadados de origem (`nome_arquivo_origem`). |
| **Silver** | Limpeza e Padroniza√ß√£o | **US-1: Separa√ß√£o** (Dados Nacionais vs. EUA/2025). **Limpeza** (tratamento de nulos, convers√£o de tipos, tradu√ß√£o de c√≥digos de cliente, padroniza√ß√£o de regi√µes e meses). **Unifica√ß√£o** dos DataFrames Geral e Limpa. |
| **Gold** | Modelagem Anal√≠tica (DW) | Cria√ß√£o de Dimens√µes e Fatos agregados, otimizados para consultas de BI. |

---

## üìä Modelagem Anal√≠tica (Camada Gold)

A Camada Gold cont√©m as seguintes tabelas Fato e Dimens√£o, que atendem diretamente aos requisitos de neg√≥cio (User Stories):

### Tabelas Fato (ft\_)

| Tabela | Granularidade | User Story Atendida |
| :--- | :--- | :--- |
| `ft_consumo_mensal_regional` | Consumo e Custo por Regi√£o e M√™s | **US-3.1:** An√°lise de Tend√™ncias e Picos de Demanda. |
| `ft_custo_segmento` | Custo M√©dio por Kw/h por Tipo de Cliente | **US-3.2:** Avalia√ß√£o de Precifica√ß√£o e Rentabilidade. |
| `ft_consumo_mensal_cidade` | Consumo e Custo agregado por Cidade e M√™s | **US-3.4:** Comparativo de Uso Energ√©tico entre Cidades. |
| `ft_consumo_mensal_comparativo` | Consumo por M√™s e Tipo de Consumo (Geral vs. Limpa) | **US-5:** Comparativo de fontes de energia. |

### Tabelas Dimens√£o (d\_)

| Tabela | Granularidade | Fun√ß√£o |
| :--- | :--- | :--- |
| `d_localidade` | Regi√£o, Cidade e Bairro | **US-3.3:** Permite filtragem geogr√°fica granular em pain√©is de BI. |

---

## üõ†Ô∏è Como Executar o Projeto

1.  **Configura√ß√£o do Ambiente:** Necess√°rio um cluster Databricks (vers√£o DBR 11.3 LTS ou superior recomendada) com suporte ao Delta Lake.
2.  **Ingest√£o de Dados:** Certifique-se de que os arquivos CSV brutos (`*2023.csv`, `*2024.csv`, `*2025.csv`) estejam acess√≠veis no caminho definido para a Camada Bronze (volume/path).
3.  **Execu√ß√£o Sequencial:** Os notebooks devem ser executados na ordem da arquitetura:
    * `notebook_bronze.py` (ou notebook de Ingest√£o)
    * `notebook_silver.py` (Limpeza e Separa√ß√£o)
    * `notebook_gold.py` (Modelagem Anal√≠tica)
