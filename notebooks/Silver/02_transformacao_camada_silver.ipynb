{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f61d3144-86b5-4256-9b95-d3f09662ea57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81683e04-e479-4ceb-9d08-53f55679c700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definindo o catálogo e schemas\n",
    "CATALOGO = \"catalogo_energia\"\n",
    "SCHEMA_BRONZE = \"bronze\"\n",
    "SCHEMA_SILVER = \"silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "925cfc96-3ed8-4f33-bdd1-0b9c8463d750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lendo as tabelas Delta da camada Bronze\n",
    "df_geral_bronze = spark.read.table(f\"{CATALOGO}.{SCHEMA_BRONZE}.consumo_geral\")\n",
    "df_limpa_bronze = spark.read.table(f\"{CATALOGO}.{SCHEMA_BRONZE}.energia_limpa\")\n",
    "\n",
    "print(f\"Total de linhas (Geral): {df_geral_bronze.count()}\")\n",
    "print(f\"Total de linhas (Limpa): {df_limpa_bronze.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f1d04ef-e05a-48f2-a135-2c6ac784dadf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpar_e_padronizar(df):\n",
    "    \n",
    "    # 1. Tratamento de Nulos em Colunas Numéricas\n",
    "    # Substituir nulos por 0 nas colunas que serão usadas em cálculos.\n",
    "    colunas_numericas = [\"consumo_em_kw\", \"valor_da_conta\", \"valor_de_imposto\"]\n",
    "    df = df.fillna(0, subset=colunas_numericas)\n",
    "    \n",
    "    # 2. Padronização de Colunas de Texto\n",
    "    # Garante consistência de agrupamento para a análise.\n",
    "    colunas_texto_chave = [\"regiao\", \"cidade\", \"bairro\", \"tipo_de_cliente\"]\n",
    "    \n",
    "    for col in colunas_texto_chave:\n",
    "        # F.trim: remove espaços antes/depois; F.initcap: 'sao paulo' -> 'Sao Paulo'.\n",
    "        df = df.withColumn(col, F.initcap(F.trim(F.col(col))))\n",
    "\n",
    "    # 3. Conversão de Tipos (Cast) - Garantindo DoubleType para precisão\n",
    "    for col in colunas_numericas:\n",
    "        df = df.withColumn(col, F.col(col).cast(DoubleType()))\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Aplicando a função em ambos os DataFrames\n",
    "df_geral_limpo = limpar_e_padronizar(df_geral_bronze)\n",
    "df_limpa_limpo = limpar_e_padronizar(df_limpa_bronze)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_transformacao_camada_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
